# -*- coding: utf-8 -*-
"""Hybrid CNN-LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S2H0Eew_1rg8ju7vpB6y2rY--o4rIUvk

# Import Libraries
"""

import pandas as pd
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.manifold import Isomap
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, SimpleRNN, Dropout
from tensorflow.keras.models import Model
from keras.layers import Input, InputLayer
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingRegressor
from keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.tree import DecisionTreeRegressor

import numpy as np
import math
from sklearn.preprocessing import StandardScaler,MinMaxScaler, RobustScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split
import csv
from keras.optimizers import Adam
from sklearn.model_selection import TimeSeriesSplit
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline
import seaborn as sns
from tensorflow.keras.regularizers import l2
from sklearn.decomposition import PCA


plt.style.use('fivethirtyeight')
plt.rcParams['axes.facecolor'] = 'white'  # Set the axes background color to white
plt.rcParams['figure.facecolor'] = 'white'  # Set the figure background color to white         # Axes background color
plt.rcParams['axes.labelcolor'] = 'black'  # Set x and y label colors to black
plt.rcParams['xtick.color'] = 'black'  # Set x-tick color to black
plt.rcParams['ytick.color'] = 'black'  # Set y-tick color to black

"""# Analysis"""

data = pd.read_csv("Greenhouse_climate.csv")
data["AssimLight"] = np.where(data["AssimLight"] <50 , "OFF", "ON")
data["AssimLight"].describe()
#sns.countplot(data=data['AssimLight'])

data['AssimLight'].value_counts().plot(kind='bar')
plt.ylabel('Count')
plt.xlabel('AssimLight')
plt.savefig("AssimLight.png", dpi = 200)
plt.show()

dt =pd.read_csv("Greenhouse_climate.csv")
dt.boxplot(column =['BlackScr'])
plt.savefig('Curt.png', dpi = 200)
plt.show()

sns.distplot(a=dt['BlackScr'], hist=False)

"""# Data Preprocessing"""

data = pd.read_csv("Greenhouse_climate.csv")
data = data.drop(['GHtime','EnScr'], axis = 1)
data = data.dropna()
data.drop(data.tail(13).index,inplace = True)

scaler_minmax = MinMaxScaler()
scaler_standard = StandardScaler()
scaler_robust = RobustScaler()
#data = scaler.fit_transform(data)
#Y = data[:, -1] # for last column
#X = data[:, :-1] # all columns except the last one
data
data[['CO2air']] = scaler_standard.fit_transform(data[['CO2air']])

# Applying MinMaxScaler to CO2 dosage (scaling between 0 and 1)
data['PipeGrow'] = scaler_minmax.fit_transform(data[['PipeGrow']])
data['BlackScr'] = scaler_minmax.fit_transform(data[['BlackScr']])
data['AssimLight'] = scaler_minmax.fit_transform(data[['AssimLight']])

# Applying RobustScaler to soil_ph and soil_ec (handling outliers)
data[['VentLee', 'RHair', 'Tair', 'Ventwind', 'PipeLow','HumDef']] = scaler_robust.fit_transform(data[['VentLee', 'RHair', 'Tair', 'Ventwind', 'PipeLow','HumDef']])

"""Reshape data"""

df = data
timestep = 288
new_data = []
for i in range(115):
    new_data.append(df[i:i+timestep])

X = np.array(new_data)

# Print the shapes of the reshaped arrays
print("X shape:", X.shape)
X = X.reshape(115,288,10,1)

"""# PCA"""

pcas = []
ncomponents=9
for matrix in new_data:
  pca = PCA(ncomponents)  # Retain 95% of the variance

  # Fit PCA on the scaled data
  pca_components = pca.fit_transform(matrix)

  pcas.append(pca_components.flatten()[:ncomponents])

print(pcas)

"""Analyze results"""

df_pca = pd.DataFrame(pcas)
df_pca.describe()

"""save features"""

data2 = pd.read_csv("Irrigation.csv")


scaler_minmax = MinMaxScaler()
scaler_standard = StandardScaler()
scaler_robust = RobustScaler()


data2[['EC_Drain']] = scaler_standard.fit_transform(data2[['EC_Drain']])




# Applying RobustScaler to soil_ph and soil_ec (handling outliers)
data2[['pH_Drain']] = scaler_robust.fit_transform(data2[['pH_Drain']])

first = []
for i in range(0,ncomponents):
  first.append("Parameter"+str(i))
first.append("pH_Drain")
first.append("EC_Drain")
first.append("water")

with open('new_featuresPCA.csv','w') as out:
    csv_out=csv.writer(out)
    i = 0
    csv_out.writerow(first)
    for index, row in df_pca.iterrows():
        row = np.append(row, np.array([data2["pH_Drain"][i], data2["EC_Drain"][i], data2["water"][i]]))
        #print(len(row))
        csv_out.writerow(row)
        i = i+1

    # You can also do csv_out.writerows(data) instead of the for loop

"""# TSNE"""

tsnes = []
ncomponents=2
for matrix in new_data:
  tsne = TSNE(ncomponents)  # Retain 95% of the variance

  # Fit tsne on the scaled data
  tsne_components = tsne.fit_transform(matrix)

  tsnes.append(tsne_components.flatten()[:ncomponents])

print(tsnes)

"""Analyze results"""

df_pca = pd.DataFrame(tsnes)
df_pca.describe()

"""save features"""

data2 = pd.read_csv("Irrigation.csv")


scaler_minmax = MinMaxScaler()
scaler_standard = StandardScaler()
scaler_robust = RobustScaler()


data2[['EC_Drain']] = scaler_standard.fit_transform(data2[['EC_Drain']])




# Applying RobustScaler to soil_ph and soil_ec (handling outliers)
data2[['pH_Drain']] = scaler_robust.fit_transform(data2[['pH_Drain']])

first = []
for i in range(0,ncomponents):
  first.append("Parameter"+str(i))
first.append("pH_Drain")
first.append("EC_Drain")
first.append("water")

with open('new_featuresTSNE.csv','w') as out:
    csv_out=csv.writer(out)
    i = 0
    csv_out.writerow(first)
    for index, row in df_pca.iterrows():
        row = np.append(row, np.array([data2["pH_Drain"][i], data2["EC_Drain"][i], data2["water"][i]]))
        #print(len(row))
        csv_out.writerow(row)
        i = i+1

    # You can also do csv_out.writerows(data) instead of the for loop

"""# ISOMAP"""

isomaps = []
ncomponents=9
for matrix in new_data:
  isomap = Isomap(n_components=ncomponents)  # Retain 95% of the variance

  # Fit isomap on the scaled data
  isomap_components = isomap.fit_transform(matrix)

  isomaps.append(isomap_components.flatten()[:ncomponents])

print(isomaps)

"""Analyze results"""

df_pca = pd.DataFrame(isomaps)
df_pca.describe()

"""save features"""

data2 = pd.read_csv("Irrigation.csv")


scaler_minmax = MinMaxScaler()
scaler_standard = StandardScaler()
scaler_robust = RobustScaler()


data2[['EC_Drain']] = scaler_standard.fit_transform(data2[['EC_Drain']])




# Applying RobustScaler to soil_ph and soil_ec (handling outliers)
data2[['pH_Drain']] = scaler_robust.fit_transform(data2[['pH_Drain']])

first = []
for i in range(0,ncomponents):
  first.append("Parameter"+str(i))
first.append("pH_Drain")
first.append("EC_Drain")
first.append("water")

with open('new_featuresISOMAP.csv','w') as out:
    csv_out=csv.writer(out)
    i = 0
    csv_out.writerow(first)
    for index, row in df_pca.iterrows():
        row = np.append(row, np.array([data2["pH_Drain"][i], data2["EC_Drain"][i], data2["water"][i]]))
        #print(len(row))
        csv_out.writerow(row)
        i = i+1

    # You can also do csv_out.writerows(data) instead of the for loop

"""# Design Model"""

model = Sequential()

# Add CNN layers for feature extraction
model.add(Conv2D(16, (2,2), activation='relu', input_shape=(288, 10, 1), padding='same'))
model.add(MaxPooling2D())
model.add(Conv2D(32, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D())
model.add(Conv2D(64, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D())
model.add(Flatten())

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['mse'])

# Print the model summary
model.summary()

flatten_output = model.predict(X)
print(flatten_output)

print(len(flatten_output[114]))

"""# Save features"""

data2 = pd.read_csv("Irrigation.csv")


scaler_minmax = MinMaxScaler()
scaler_standard = StandardScaler()
scaler_robust = RobustScaler()


data2[['EC_Drain']] = scaler_standard.fit_transform(data2[['EC_Drain']])




# Applying RobustScaler to soil_ph and soil_ec (handling outliers)
data2[['pH_Drain']] = scaler_robust.fit_transform(data2[['pH_Drain']])

first = []
for i in range(0,2304):
  first.append("Parameter"+str(i))
first.append("pH_Drain")
first.append("EC_Drain")
first.append("water")

with open('new_features.csv','w') as out:
    csv_out=csv.writer(out)
    i = 0
    csv_out.writerow(first)
    for row in flatten_output:
        row = np.append(row, np.array([data2["pH_Drain"][i], data2["EC_Drain"][i], data2["water"][i]]))
        #print(len(row))
        csv_out.writerow(row)
        i = i+1

    # You can also do csv_out.writerows(data) instead of the for loop

"""# Clean data"""

def clean_dataset(df):
    assert isinstance(df, pd.DataFrame), "df needs to be a pd.DataFrame"
    df.dropna(inplace=True)
    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)
    return df[indices_to_keep].astype(np.float64)

"""# Data Preparation"""

def remove_const(df):
  #for i in range(0,2304):
  for i in range(0,ncomponents):
    #data = clean_dataset(data)
    if all(df['Parameter'+str(i)] == 0):
        # Drop the column if the condition is met
        df.drop('Parameter'+str(i), axis=1, inplace=True)
  return df

data = pd.read_csv("new_featuresISOMAP.csv")
#data = data.dropna(axis=0, how='any', subset=None, inplace=False)
data = data.dropna()
data.replace([np.inf, -np.inf], 1, inplace=True)
data = remove_const(data)
data = data.reset_index()
data.describe()

Y = data.iloc[ :, -1:]
Y = Y.values.reshape(-1, 1) # Convert to a NumPy array and reshape to a column vector
data.pop(data.columns[-1])
data = data.reset_index(drop= True)
#data = scaler.fit_transform(data)
#Y = data[:, -1] # for last column
#X = data[:, :-1] # all columns except the last one

X = data.to_numpy()
data.describe()

x_train, x_test, y_train, y_test = train_test_split(X,Y, shuffle=True,test_size=0.3)
#y_train = y_train.values()
#y_test =  y_test.values()
print(y_test)
#x_train = x_test = X
#y_train = y_test = Y

def prep_X(datain, time_step):
    #datain = datain.drop(['water'], axis = 1)
    # 1. y-array
    # First, create an array with indices for y elements based on the chosen time_step
    result = []
    for i in range(0,len(datain)-time_step):
      mat = []
      for j in range(i,i+time_step):
        mat.append(datain[j])
      result.append(mat)
    return result

def inputPrep(x_train,x_test,y_train,y_test,time):
  x_tr = np.array(prep_X(x_train, int(time)))
  x_t = np.array(prep_X(x_test, int(time)))
  y_tr = np.array(y_train[int(time):])
  y_t = np.array(y_test[int(time):])
  return x_tr,x_t,y_tr,y_t



def predictions(y1,y_ti,y_predi):
  plt.figure(figsize=(17,10))
  y_pred = list(y_predi)
  y_t = list(y_ti)
  plt.plot(y_pred, color='red', linestyle='--',label='Predicted')
  plt.plot(y_t, color='blue', linestyle='--',label='Actual', linewidth=6)
  plt.xlabel('Time')
  plt.ylabel('Value')
  plt.legend()
  plt.savefig("res1.png", dpi=150)
  plt.show()

def plotCurves(history):
  train_loss = history.history['loss']
  valid_loss = history.history['val_loss']
  epochs = range(1, len(train_loss) + 1)
  plt.plot(epochs, train_loss, label='Training Loss')
  plt.plot(epochs, valid_loss, label='Validation Loss')
  plt.xlabel('Epochs')
  plt.ylabel('Loss')
  plt.title('Loss Curve')
  plt.legend()
  plt.savefig("res2.png", dpi=150)
  plt.show()

def plotPVT(y_t,y_pred):
  plt.figure(figsize=(8, 8))
  fig = plt.gcf()
  fig.patch.set_facecolor('white')
  plt.scatter(y_t, y_pred, alpha=0.6)
  plt.plot([min(list(y_t)), max(list(y_t))], [min(list(y_t)), max(list(y_t))], color='red', linestyle='--', label='Diagonal Line', linewidth=6)
  plt.xlabel('True Values')
  plt.ylabel('Predicted Values')
  plt.grid(linestyle="dashdot",alpha=0.5,zorder=1)
  plt.title('True vs. Predicted Values Scatter Plot')
  plt.savefig("res3.png", dpi = 200)
  plt.show()

"""# HP Tuninig"""

import itertools

alpha = [0.1, 0.01, 0.001, 0.0001]
nbU = [20,40,60,80,100, 120]
nbL = [1,2,3,4,5]
drops = [0,0.1,0.2,0.3]
combinations = list(itertools.product(alpha, nbU,nbL,drops))

results = []
for iter in combinations:
  v1,v2,v3,v4 = iter
  time = 2
#x_tr,x_t,y_tr,y_t = inputPrep(x_train,x_test,y_train,y_test,time)
  model = Sequential()
  # Defining the first layer of the model

  model.add(Input(shape=(1949,), name='Input-Layer'))
  for i in range(v3):
    model.add(Dense(v2, activation = 'relu', #kernel_regularizer=l2(0.001),
          ))
    model.add(Dropout(v4))






  model.add(Dense(1))

  optimizerr = Adam(learning_rate= v1)
  # Compiling the model
  model.compile(loss='mean_absolute_error', optimizer=optimizerr)
  #print(X_tr.shape[1])
  #X_val = X_val[:, np.newaxis]
  model.fit(x_train,y_train, epochs=100,validation_data=(x_test,y_test), batch_size= 16,shuffle=False, verbose = None,
            #callbacks=[early_stop]
                  )
  y_pred = model.predict(x_test)  # Adjust as per your model
  mae_score = np.mean(mean_absolute_error(y_test, y_pred))
  print("MAE = ",mae_score)
  results.append([v1,v2,v3,v4,mae_score])
hp = pd.DataFrame(results,
                  columns=['Learning rate', 'Nb. Units', 'Nb. Layers', 'Dropout', 'MAE'])
hp.to_csv("hp.csv")

hp.nsmallest(n=1, columns="MAE")

"""# Prediction"""

early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1)
checkpoint_path = "stability_checkpoint..weights.h5"
checkpoint = ModelCheckpoint(
    checkpoint_path,
    monitor='val_loss',
    save_best_only=True,
    save_weights_only=True,
    mode='min',
    verbose=1
)

time = 2
#x_tr,x_t,y_tr,y_t = inputPrep(x_train,x_test,y_train,y_test,time)
model = Sequential()
# Defining the first layer of the model

model.add(Input(shape=(12,), name='Input-Layer'))
model.add(Dense(100, activation = 'relu', #kernel_regularizer=l2(0.001),
        ))
model.add(Dropout(0.3))






model.add(Dense(1))

optimizerr = Adam(learning_rate= 0.001)
# Compiling the model
model.compile(loss='mean_squared_error', optimizer=optimizerr)
#print(X_tr.shape[1])
#X_val = X_val[:, np.newaxis]
history = model.fit(x_train,y_train, epochs=100,validation_data=(x_test,y_test), batch_size= 16,shuffle=False,
          #callbacks=[early_stop]
                )


y_pred = model.predict(x_test)  # Adjust as per your model
rmse_score = math.sqrt(np.mean(mean_squared_error(y_test, y_pred)))
mae_score = np.mean(mean_absolute_error(y_test, y_pred))
r2 = np.mean(r2_score(y_test, y_pred))
mape = np.mean(np.abs((y_test - y_pred) / y_test) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

predictions(y_train,y_test,y_pred)

plotCurves(history)

train_loss = model.evaluate(x_train, y_train)
test_loss = model.evaluate(x_test, y_test)
print("Training Loss:", train_loss)
print("Testing Loss:", test_loss)

plotPVT(y_test,y_pred)

"""# MLP model evaluation"""

x_train_old, x_test_old, y_train_old, y_test_old = x_train, x_test, y_train, y_test
#print (y_test_old)

"""SVR"""

model = make_pipeline(MinMaxScaler(), SVR())
model.fit(x_train_old,y_train_old)


y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), y_pred, alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For SVR model')
plt.savefig("svrTvP1.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_test_old)
plt.plot(y_pred, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of SVR model')
plt.savefig("svr1.png", dpi=150)
plt.show()

"""GBR"""

model = GradientBoostingRegressor(n_estimators=9, random_state=0)
model.fit(x_train_old, y_train_old)
y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For GBR model')
plt.savefig("gbrTvP1.png", dpi = 200)
plt.show()

"""DTR"""

model = DecisionTreeRegressor(random_state=0)
model.fit(x_train_old, y_train_old)
y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For DTR model')
plt.savefig("dtrTvP.png", dpi = 200)
plt.show()

"""RFR"""

model = RandomForestRegressor(max_depth=6)
model.fit(x_train_old, y_train_old)
y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For RFR model')
plt.savefig("rfrTvP1.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_test_old)
plt.plot(y_pred, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of RFR model')
plt.savefig("rfr.png", dpi=150)
plt.show()

"""RNN"""

x_tr_old = x_train_old.reshape((x_train_old.shape[0], 1, x_train_old.shape[1]))
x_t_old = x_test_old.reshape((x_test_old.shape[0], 1, x_test_old.shape[1]))


#x_tr_old = np.array(prep_X(x_train_old, 1))
#x_t_old = np.array(prep_X(x_test_old, 1))
y_tr_old = np.array(y_train_old)
y_t_old = np.array(y_test_old)


rnns = Sequential()
rnns.add(Input(shape=(1,1949)))
rnns.add(SimpleRNN(128,activation = 'tanh'))
#rnns.add(Dense(128,activation = 'relu'))
rnns.add(Dense(1))

rnns.compile(loss='mean_absolute_error', optimizer='adam')
#generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=t, batch_size=32)
# Fitting the rnn to the Training set
rnns.fit(x_tr_old, y_tr_old, batch_size = 32, shuffle = True, epochs=100, verbose = 2)
#test_generator = TimeseriesGenerator(scaled_X_test, np.zeros(len(X_test)), length=t, batch_size=32)
y_pred_old2 = rnns.predict(x_t_old)

mae = np.mean(mean_absolute_error(y_t_old,y_pred_old2))
rmse = math.sqrt(np.mean(mean_squared_error(y_t_old,y_pred_old2)))
r2 = np.mean(r2_score(list(y_t_old), y_pred_old2))
mape = np.mean(np.abs((list(y_t_old) - y_pred_old2) / list(y_t_old)) * 100)
print("---------------------------------")
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(y_t_old, y_pred_old2, alpha=0.6)
plt.plot([min(y_t_old), max(y_t_old)], [min(y_t_old), max(y_t_old)], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot')
plt.savefig("rnnTvP.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_t_old)
plt.plot(y_pred_old2, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of RNN model')
plt.savefig("rnn1.png", dpi=150)
plt.show()

"""LSTM"""

lstm = Sequential()
lstm.add(Input(shape=(1,1949)))
lstm.add(LSTM(128,activation = 'relu'))
#lstm.add(Dense(128,activation = 'relu'))
lstm.add(Dense(1))

lstm.compile(loss='mean_absolute_error', optimizer='adam')
#generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=t, batch_size=32)
# Fitting the rnn to the Training set
lstm.fit(x_tr_old, y_tr_old, batch_size = 32, shuffle = True, epochs=100, verbose = 2)
#test_generator = TimeseriesGenerator(scaled_X_test, np.zeros(len(X_test)), length=t, batch_size=32)
y_pred_old2 = lstm.predict(x_t_old)

mae = np.mean(mean_absolute_error(y_t_old,y_pred_old2))
rmse = math.sqrt(np.mean(mean_squared_error(y_t_old,y_pred_old2)))
r2 = np.mean(r2_score(list(y_t_old), y_pred_old2))
mape = np.mean(np.abs((list(y_t_old) - y_pred_old2) / list(y_t_old)) * 100)
print("---------------------------------")
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(y_t_old, y_pred_old2, alpha=0.6)
plt.plot([min(y_t_old), max(y_t_old)], [min(y_t_old), max(y_t_old)], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot')
plt.savefig("lstmTvP1.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_t_old)
plt.plot(y_pred_old2, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of LSTM model')
plt.savefig("lstm1.png", dpi=150)
plt.show()

"""# Proposed approach evaluation"""

data_old = pd.read_csv("Output.csv")
data_old = data_old.dropna(axis=0)
data_old = data_old.drop(['Unnamed: 0','Daily Temperature','Daily Wind','Daily Humidity','Daily Cumulative UV'], axis = 1)
data_old = data_old.reset_index()
data_old.describe()

Y_old = data_old.iloc[ :, -1:]
data_old.pop(data_old.columns[-1])

scaler = MinMaxScaler(feature_range=(0, 1))

X_old = scaler.fit_transform(data_old)

x_train_old, x_test_old, y_train_old, y_test_old = train_test_split(X_old,Y_old, shuffle=True, test_size=0.3)
y_test_old = list(y_test_old['water'])
#print (y_test_old)

"""SVR"""

model = make_pipeline(MinMaxScaler(), SVR())
model.fit(x_train_old,y_train_old)


y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), y_pred, alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For SVR model')
plt.savefig("svrTvP2.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_test_old)
plt.plot(y_pred, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of SVR model')
plt.savefig("svr2.png", dpi=150)
plt.show()

"""RFR"""

model = RandomForestRegressor()
model.fit(x_train_old, y_train_old)
y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For RFR model')
plt.savefig("rfrTvP2.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_test_old)
plt.plot(y_pred, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of RFR model')
plt.savefig("rfr2.png", dpi=150)
plt.show()

"""GBR"""

model = GradientBoostingRegressor(n_estimators=9, random_state=0)
model.fit(x_train_old, y_train_old)
y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For GBR model')
plt.savefig("gbrTvP2.png", dpi = 200)
plt.show()

"""DTR"""

model = DecisionTreeRegressor(random_state=0)
model.fit(x_train_old, y_train_old)
y_pred = model.predict(x_test_old)
rmse_score = math.sqrt(np.mean(mean_squared_error(list(y_test_old), y_pred)))
mae_score = np.mean(mean_absolute_error(list(y_test_old), y_pred))
r2 = np.mean(r2_score(list(y_test_old), y_pred))
mape = np.mean(np.abs((list(y_test_old) - y_pred) / list(y_test_old)) * 100)
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot For DTR model')
plt.savefig("dtrTvP2.png", dpi = 200)
plt.show()

"""ANN"""

ann = Sequential()
ann.add(InputLayer(input_shape=(11,)))
ann.add(Dense(128,activation = 'relu'))
ann.add(Dense(1))

ann.compile(loss='mean_absolute_error', optimizer='adam')
#generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=t, batch_size=32)
# Fitting the ANN to the Training set
ann.fit(x_train_old, y_train_old, batch_size = 32, shuffle = True, epochs=100, verbose = 2)
#test_generator = TimeseriesGenerator(scaled_X_test, np.zeros(len(X_test)), length=t, batch_size=32)
y_pred_old = ann.predict(x_test_old)

mae = np.mean(mean_absolute_error(y_test_old,y_pred_old))
rmse = math.sqrt(np.mean(mean_squared_error(y_test_old,y_pred_old)))
r2 = np.mean(r2_score(list(y_test_old), y_pred_old))
mape = np.mean(np.abs((list(y_test_old) - y_pred_old) / list(y_test_old)) * 100)
print("---------------------------------")
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)
plt.figure(figsize=(8, 8))
plt.scatter(list(y_test_old), list(y_pred_old), alpha=0.6)
plt.plot([min(list(y_test_old)), max(list(y_test_old))], [min(list(y_test_old)), max(list(y_test_old))], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot')
plt.savefig("annTvP2.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_test_old)
plt.plot(y_pred_old, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of MLP model')
plt.savefig("ann2.png", dpi=150)
plt.show()

"""RNN"""

x_tr_old = np.array(prep_X(x_train_old, 1))
x_t_old = np.array(prep_X(x_test_old, 1))
y_tr_old = np.array(y_train_old[1:])
y_t_old = np.array(y_test_old[1:])


rnns = Sequential()
rnns.add(Input(shape=(1,11)))
rnns.add(SimpleRNN(128,activation = 'relu'))
#rnns.add(Dense(128,activation = 'relu'))
rnns.add(Dense(1))

rnns.compile(loss='mean_absolute_error', optimizer='adam', run_eagerly=True)
#generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=t, batch_size=32)
# Fitting the rnn to the Training set
rnns.fit(x_tr_old, y_tr_old, batch_size = 32, shuffle = True, epochs=100, verbose = 2)
#test_generator = TimeseriesGenerator(scaled_X_test, np.zeros(len(X_test)), length=t, batch_size=32)
y_pred_old2 = rnns.predict(x_t_old)

mae = np.mean(mean_absolute_error(y_t_old,y_pred_old2))
rmse = math.sqrt(np.mean(mean_squared_error(y_t_old,y_pred_old2)))
r2 = np.mean(r2_score(list(y_t_old), y_pred_old2))
mape = np.mean(np.abs((list(y_t_old) - y_pred_old2) / list(y_t_old)) * 100)
print("---------------------------------")
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(y_t_old, y_pred_old2, alpha=0.6)
plt.plot([min(y_t_old), max(y_t_old)], [min(y_t_old), max(y_t_old)], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot')
plt.savefig("rnnTvP2.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_t_old)
plt.plot(y_pred_old2, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of RNN model')
plt.savefig("rnn2.png", dpi=150)
plt.show()

"""LSTM"""

lstm = Sequential()
lstm.add(Input(shape=(1,11)))
lstm.add(LSTM(128,activation = 'relu'))
#lstm.add(Dense(128,activation = 'relu'))
lstm.add(Dense(1))

lstm.compile(loss='mean_absolute_error', optimizer='adam')
#generator = TimeseriesGenerator(scaled_X_train, scaled_y_train, length=t, batch_size=32)
# Fitting the rnn to the Training set
lstm.fit(x_tr_old, y_tr_old, batch_size = 32, shuffle = True, epochs=100, verbose = 2)
#test_generator = TimeseriesGenerator(scaled_X_test, np.zeros(len(X_test)), length=t, batch_size=32)
y_pred_old2 = lstm.predict(x_t_old)

mae = np.mean(mean_absolute_error(y_t_old,y_pred_old2))
rmse = math.sqrt(np.mean(mean_squared_error(y_t_old,y_pred_old2)))
r2 = np.mean(r2_score(list(y_t_old), y_pred_old2))
mape = np.mean(np.abs((list(y_t_old) - y_pred_old2) / list(y_t_old)) * 100)
print("---------------------------------")
print("RMSE = ",rmse_score)
print("MAE = ",mae_score)
print("R2 = ",r2)
print("MAPE = ",mape)

plt.figure(figsize=(8, 8))
plt.scatter(y_t_old, y_pred_old2, alpha=0.6)
plt.plot([min(y_t_old), max(y_t_old)], [min(y_t_old), max(y_t_old)], color='red', linestyle='--', label='Diagonal Line')
plt.xlabel('True Values')
plt.ylabel('Predicted Values')
plt.title('True vs. Predicted Values Scatter Plot')
plt.savefig("lstmTvP2.png", dpi = 200)
plt.show()

plt.figure(figsize=(17,10))
y_t = list(y_t_old)
plt.plot(y_pred_old2, color='red', linestyle='--',label='Predicted')
plt.plot(y_t, color='blue', linestyle='-',label='Actual')
plt.xlabel('Time')
plt.ylabel('Value')
plt.title('Prediction result of LSTM model')
plt.savefig("lstm2.png", dpi=150)
plt.show()

"""# Other"""

rslt_df = hp.loc[(hp['Dropout'] == 0.3) & (hp['Nb. Units'] == 100) & (hp['Nb. Layers'] == 1)]

print('\nResult dataframe :\n', rslt_df)

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'Helvetica'

# set the style of the axes and the text color
plt.rcParams['axes.edgecolor']='#333F4B'
plt.rcParams['axes.linewidth']=0.8
plt.rcParams['xtick.color']='#333F4B'
plt.rcParams['ytick.color']='#333F4B'
plt.rcParams['text.color']='#333F4B'

# create some fake data
MAEs = pd.Series([0.686076, 0.710549, 0.386860, 0.430781],
                        index=['0.1', '0.01', '0.001', '0.0001'])
df = pd.DataFrame({'MAE' : MAEs})

# we first need a numeric placeholder for the y axis
my_range=list(range(1,len(df.index)+1))

fig, ax = plt.subplots(figsize=(5,3.5))

# create for each expense type an horizontal line that starts at x = 0 with the length
# represented by the specific expense MAE value.
plt.hlines(y=my_range, xmin=0, xmax=df['MAE'], color='#007ACC', alpha=0.3, linewidth=5)

# create for each expense type a dot at the level of the expense MAE value
plt.plot(df['MAE'], my_range, "o", markersize=5, color='#007ACC', alpha=0.8)

# set labels
ax.set_xlabel('MAE', fontsize=15, fontweight='black', color = '#333F4B')
ax.set_ylabel('')

# set axis
ax.tick_params(axis='both', which='major', labelsize=12)
plt.yticks(my_range, df.index)

# add an horizonal label for the y axis
fig.text(-0.23, 0.96, 'Apha Values', fontsize=15, fontweight='black', color = '#333F4B')

# change the style of the axis spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

ax.spines['left'].set_bounds((1,len(my_range)))
#ax.set_xlim(0,25)

ax.spines['left'].set_position(('outward', 8))
ax.spines['bottom'].set_position(('outward', 5))

plt.savefig('alpha.png', dpi=300, bbox_inches='tight')

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'Helvetica'

# set the style of the axes and the text color
plt.rcParams['axes.edgecolor']='#333F4B'
plt.rcParams['axes.linewidth']=0.8
plt.rcParams['xtick.color']='#333F4B'
plt.rcParams['ytick.color']='#333F4B'
plt.rcParams['text.color']='#333F4B'

# create some fake data
MAEs = pd.Series([0.641267, 0.409330, 0.438896, 0.386860],
                        index=['0', '0.1', '0.2', '0.3'])
df = pd.DataFrame({'MAE' : MAEs})

# we first need a numeric placeholder for the y axis
my_range=list(range(1,len(df.index)+1))

fig, ax = plt.subplots(figsize=(5,3.5))

# create for each expense type an horizontal line that starts at x = 0 with the length
# represented by the specific expense MAE value.
plt.hlines(y=my_range, xmin=0, xmax=df['MAE'], color='#007ACC', alpha=0.3, linewidth=5)

# create for each expense type a dot at the level of the expense MAE value
plt.plot(df['MAE'], my_range, "o", markersize=5, color='#007ACC', alpha=0.8)

# set labels
ax.set_xlabel('MAE', fontsize=15, fontweight='black', color = '#333F4B')
ax.set_ylabel('')

# set axis
ax.tick_params(axis='both', which='major', labelsize=12)
plt.yticks(my_range, df.index)

# add an horizonal label for the y axis
fig.text(-0.23, 0.96, 'Dropout', fontsize=15, fontweight='black', color = '#333F4B')

# change the style of the axis spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

ax.spines['left'].set_bounds((1,len(my_range)))
#ax.set_xlim(0,25)

ax.spines['left'].set_position(('outward', 8))
ax.spines['bottom'].set_position(('outward', 5))

plt.savefig('drop.png', dpi=300, bbox_inches='tight')

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'Helvetica'

# set the style of the axes and the text color
plt.rcParams['axes.edgecolor']='#333F4B'
plt.rcParams['axes.linewidth']=0.8
plt.rcParams['xtick.color']='#333F4B'
plt.rcParams['ytick.color']='#333F4B'
plt.rcParams['text.color']='#333F4B'

# create some fake data
MAEs = pd.Series([0.450033, 0.399201, 0.502061, 0.442441, 0.386860, 0.503926],
                        index=['20', '40', '60', '80', '100', '120'])
df = pd.DataFrame({'MAE' : MAEs})

# we first need a numeric placeholder for the y axis
my_range=list(range(1,len(df.index)+1))

fig, ax = plt.subplots(figsize=(5,3.5))

# create for each expense type an horizontal line that starts at x = 0 with the length
# represented by the specific expense MAE value.
plt.hlines(y=my_range, xmin=0, xmax=df['MAE'], color='#007ACC', alpha=0.3, linewidth=5)

# create for each expense type a dot at the level of the expense MAE value
plt.plot(df['MAE'], my_range, "o", markersize=5, color='#007ACC', alpha=0.8)

# set labels
ax.set_xlabel('MAE', fontsize=15, fontweight='black', color = '#333F4B')
ax.set_ylabel('')

# set axis
ax.tick_params(axis='both', which='major', labelsize=12)
plt.yticks(my_range, df.index)

# add an horizonal label for the y axis
fig.text(-0.23, 0.96, 'Nb. Units', fontsize=15, fontweight='black', color = '#333F4B')

# change the style of the axis spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

ax.spines['left'].set_bounds((1,len(my_range)))
#ax.set_xlim(0,25)

ax.spines['left'].set_position(('outward', 8))
ax.spines['bottom'].set_position(('outward', 5))

plt.savefig('units.png', dpi=300, bbox_inches='tight')

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'Helvetica'

# set the style of the axes and the text color
plt.rcParams['axes.edgecolor']='#333F4B'
plt.rcParams['axes.linewidth']=0.8
plt.rcParams['xtick.color']='#333F4B'
plt.rcParams['ytick.color']='#333F4B'
plt.rcParams['text.color']='#333F4B'

# create some fake data
MAEs = pd.Series([0.386860, 0.613093, 1.089807, 1.243954, 1.101312],
                        index=['1', '2', '3', '4', '5'])
df = pd.DataFrame({'MAE' : MAEs})

# we first need a numeric placeholder for the y axis
my_range=list(range(1,len(df.index)+1))

fig, ax = plt.subplots(figsize=(5,3.5))

# create for each expense type an horizontal line that starts at x = 0 with the length
# represented by the specific expense MAE value.
plt.hlines(y=my_range, xmin=0, xmax=df['MAE'], color='#007ACC', alpha=0.3, linewidth=5)

# create for each expense type a dot at the level of the expense MAE value
plt.plot(df['MAE'], my_range, "o", markersize=5, color='#007ACC', alpha=0.8)

# set labels
ax.set_xlabel('MAE', fontsize=15, fontweight='black', color = '#333F4B')
ax.set_ylabel('')

# set axis
ax.tick_params(axis='both', which='major', labelsize=12)
plt.yticks(my_range, df.index)

# add an horizonal label for the y axis
fig.text(-0.23, 0.96, 'Nb. Layers', fontsize=15, fontweight='black', color = '#333F4B')

# change the style of the axis spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

ax.spines['left'].set_bounds((1,len(my_range)))
#ax.set_xlim(0,25)

ax.spines['left'].set_position(('outward', 8))
ax.spines['bottom'].set_position(('outward', 5))

plt.savefig('layers.png', dpi=300, bbox_inches='tight')

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'Helvetica'
plt.rcParams['axes.edgecolor']='#250902'


data = [['SVR', 0.463], ['RFR', 0.1672], ['DTR', 0.36],  ['RNN', 0.1672],  ['LSTM', 0.1672] , ['Proposed', 0.1516]]
df = pd.DataFrame(data, columns=['Models', 'RMSE-MAE values'])
c = ['#f9dcc4', '#e6ccb2', '#ddb892', '#b08968', '#7f5539', '#9c6644']

plt.figure(figsize=(10,7))
plt.xticks(range(6), df['Models'],weight = 'bold')
plt.xlabel('Models',fontweight='bold')
plt.ylabel('RMSE-MAE',fontweight='bold')
plt.title('RMSE-MAE Values for the Different Models')
plt.bar(range(6), df['RMSE-MAE values'], color=c, alpha=1, edgecolor = '#d7ceb2')
plt.grid(color='#87877f', linestyle='--', linewidth=2, axis='y', alpha=0.3)
plt.savefig("rmse-mae1",dpi= 250)
plt.show()

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = 'Helvetica'

# set the style of the axes and the text color
plt.rcParams['axes.edgecolor']='#333F4B'
plt.rcParams['axes.linewidth']=0.8
plt.rcParams['xtick.color']='#333F4B'
plt.rcParams['ytick.color']='#333F4B'
plt.rcParams['text.color']='#333F4B'

# create some fake data
MAEs = pd.Series([0.51, 0.61, 0.57],
                        index=['(2 , 2)', '(3 , 3)', '(4 , 4)'])
df = pd.DataFrame({'MAE' : MAEs})

# we first need a numeric placeholder for the y axis
my_range=list(range(1,len(df.index)+1))

fig, ax = plt.subplots(figsize=(5,3.5))

# create for each expense type an horizontal line that starts at x = 0 with the length
# represented by the specific expense MAE value.
plt.hlines(y=my_range, xmin=0, xmax=df['MAE'], color='#007ACC', alpha=0.3, linewidth=5)

# create for each expense type a dot at the level of the expense MAE value
plt.plot(df['MAE'], my_range, "o", markersize=5, color='#007ACC', alpha=0.8)

# set labels
ax.set_xlabel('MAE', fontsize=15, fontweight='black', color = '#333F4B')
ax.set_ylabel('')

# set axis
ax.tick_params(axis='both', which='major', labelsize=12)
plt.yticks(my_range, df.index)

# add an horizonal label for the y axis
fig.text(-0.23, 0.96, 'Kernel size', fontsize=15, fontweight='black', color = '#333F4B')

# change the style of the axis spines
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)

ax.spines['left'].set_bounds((1,len(my_range)))
#ax.set_xlim(0,25)

ax.spines['left'].set_position(('outward', 8))
ax.spines['bottom'].set_position(('outward', 5))

plt.savefig('kernel.png', dpi=300, bbox_inches='tight')